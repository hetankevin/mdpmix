{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5eda708-74e6-4df5-91e5-af19e39290c8",
   "metadata": {},
   "source": [
    "# Mixtures of MDPs -- Actual Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b77517-65de-4c39-8c5b-6c38fba0ca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "\n",
    "import sys\n",
    "# setting path\n",
    "sys.path.append('../core')\n",
    "import os\n",
    "#os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"10\"\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#bread and butter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#machine learning library\n",
    "import sklearn\n",
    "import sklearn.manifold\n",
    "import sklearn.cluster\n",
    "import sklearn.decomposition\n",
    "\n",
    "#statistics\n",
    "import scipy\n",
    "from scipy.stats import rankdata, norm\n",
    "\n",
    "import numba\n",
    "from numba import jit, njit\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "#import numpy as tnp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import dfply\n",
    "# from dfply import *\n",
    "# import ray\n",
    "# import datetime\n",
    "\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import torch\n",
    "#torch.cuda.is_available()\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import confound_mdp\n",
    "import confound_ope\n",
    "import confound_env\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from subspace import *\n",
    "from clustering import *\n",
    "from emalg import *\n",
    "from helpers import *\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('matplotlibrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74466576-da03-493c-a0c7-9eaabe01d605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLIP THIS TO TRUE IF YOU WANT TO SEE MORE PLOTS WHILE THINGS ARE RUNNING\n",
    "diagnostic = False\n",
    "\n",
    "horizons = [20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "#horizons = [100]\n",
    "\n",
    "#BY DEFAULT SET TO 30\n",
    "trials = 30\n",
    "\n",
    "\n",
    "\n",
    "clusterAccsTrials = []\n",
    "clusterAccsNoProjsTrials = []\n",
    "clusterAccsRandProjsTrials = []\n",
    "classAccsTrials = []\n",
    "classProjAccsTrials = []\n",
    "hardClustEMAccsTrials = []\n",
    "softClustEMAccsTrials = []\n",
    "hardClassEMAccsTrials = []\n",
    "softClassEMAccsTrials = []\n",
    "hardEMAccsTrials = []\n",
    "softEMAccsTrials = []\n",
    "\n",
    "for trial in range(trials):\n",
    "    clusterAccs = []\n",
    "    clusterAccsNoProjs = []\n",
    "    clusterAccsRandProjs = []\n",
    "    modelEstims = []\n",
    "    classAccs = []\n",
    "    classProjAccs = []\n",
    "    hardClustEMs = []\n",
    "    hardClustEMAccs = []\n",
    "    softClustEMs = []\n",
    "    softClustEMAccs = []\n",
    "    softClassEMs = []\n",
    "    softClassEMAccs = []\n",
    "    hardClassEMs = []\n",
    "    hardClassEMAccs = []\n",
    "    hardEMs = []\n",
    "    hardEMAccs = []\n",
    "    softEMs = []\n",
    "    softEMAccs = []\n",
    "    \n",
    "    start_seed = trial*multiprocessing.cpu_count()\n",
    "    print(\"Trial\", trial, \"with start seed\", start_seed)\n",
    "\n",
    "    for horizon in horizons:\n",
    "        print(\"Current Horizon is:\", horizon)\n",
    "\n",
    "        ###GRIDWORLD###\n",
    "    \n",
    "        pi_b, P, R, x_dist, u_dist, gamma = confound_env.gridworld_opetools(horizon = horizon, slip = 0.04, \n",
    "                                                                        confound_weight=0.6, small=False, soft=True)\n",
    "        pi_b[0] = pi_b.mean(0)\n",
    "        pi_b[1] = pi_b.mean(0)\n",
    "\n",
    "        mdp = confound_mdp.ConfoundMDP(P, R, x_dist, u_dist, gamma)\n",
    "\n",
    "        nStates = P.shape[2]\n",
    "        nActions = P.shape[1]\n",
    "\n",
    "        ###GRIDWORLD###\n",
    "\n",
    "        dataset = getSamplesMultiProc(1000, mdp, pi_b, horizon, start_seed=start_seed, iid=False)\n",
    "\n",
    "         # behavior value\n",
    "        print(\"value of pi_b\")\n",
    "        returns = confound_mdp.calc_returns(dataset, gamma, horizon)\n",
    "        print(returns.mean())\n",
    "    \n",
    "\n",
    "        stateactions = dataset[:, :, [0, 1]]\n",
    "        memorder = 'C'\n",
    "\n",
    "        if memorder == 'F':\n",
    "            stateactions = (dataset[:,:,0] + dataset[:,:,1]*nStates).astype(int) #we code (S x A) as s + a|S|, 0,16,32,48 1,17,33,49\n",
    "        else:\n",
    "            stateactions = (dataset[:,:,0]*nActions + dataset[:,:,1]).astype(int)\n",
    "        states = (dataset[:,:,0]).astype(int)\n",
    "        actions = (dataset[:,:,1]).astype(int)\n",
    "        currstates = dataset[:,:,[0,1]].astype(int)\n",
    "        confounders = dataset[:,:,2].astype(int)\n",
    "        labels = confounders[:,0].astype(int)\n",
    "        nextstates = dataset[:,:,3].astype(int)\n",
    "\n",
    "        L = 2\n",
    "        K = 2\n",
    "        #S = nStates*nActions\n",
    "        #N = len(threes)\n",
    "\n",
    "\n",
    "        ########SUBSPACE ESTIMATION########\n",
    "\n",
    "        sadim = nStates*nActions\n",
    "        spdim = nStates\n",
    "        omegaone = np.array([i for i in range(int(horizon/4), 2*int(horizon/4))])\n",
    "        omegatwo = np.array([i for i in range(3*int(horizon/4), horizon)])\n",
    "        onehotsa = np.eye(sadim)[stateactions]\n",
    "        #onehotsaflat = copy.deepcopy(onehotsa)\n",
    "        onehotsa = onehotsa.reshape((onehotsa.shape[0], onehotsa.shape[1], nStates, nActions), order=memorder)\n",
    "        onehotsp = np.eye(np.max(nextstates)+1)[nextstates]\n",
    "        sz = int(onehotsa.shape[0]/3)\n",
    "\n",
    "        eigvalsa, eigvecsa = getEig(onehotsa[:sz], onehotsp[:sz], omegaone, omegatwo, K, wt=True, smalldata=False, device='/GPU:0')\n",
    "\n",
    "        #########CLUSTERING#########\n",
    "\n",
    "        device = \"/GPU:0\"\n",
    "\n",
    "        hs = np.array([geth(onehotsa[sz:,omegaone,:,:], \n",
    "                                         onehotsp[sz:,omegaone,:]), \n",
    "                                  geth(onehotsa[sz:,omegatwo,:,:], \n",
    "                                       onehotsp[sz:,omegatwo,:])], dtype=np.float32)\n",
    "\n",
    "        statmns = computeStat(hs, \n",
    "                          eigvecsa, numpy=False, smalldata=False, device=device, proj=True)\n",
    "\n",
    "        statNoProjs = computeStat(hs, \n",
    "                          eigvecsa, numpy=False, smalldata=False, device=device, proj=False)\n",
    "        \n",
    "        randProjs = np.linalg.qr(np.random.normal(size=(nStates,nActions,nStates,K)))[0]\n",
    "        statRandProjs = computeStat(hs, \n",
    "                                    randProjs, numpy=False, smalldata=False, device=device, proj=True)\n",
    "        \n",
    "        if diagnostic:\n",
    "            clusterDiagnostics(statmns, K=K, labels=confounders[sz:, 0],\n",
    "                           lo=0, hi=0.0005, step=0.000025) #0,0.01, 0.0001\n",
    "            plt.show()\n",
    "            clusterDiagnostics(statNoProjs, K=K, labels=confounders[sz:, 0],\n",
    "                       lo=0, hi=0.0005, step=0.000025) #0,0.01, 0.0001\n",
    "            plt.show()\n",
    "            clusterDiagnostics(statRandProjs, K=K, labels=confounders[sz:, 0],\n",
    "                       lo=0, hi=0.0005, step=0.000025) #0,0.01, 0.0001\n",
    "            plt.show()\n",
    "\n",
    "        clusterlabs = sklearn.cluster.spectral_clustering((statmns < 0.0001).astype(int), n_clusters=2,\n",
    "                                                         assign_labels='kmeans')\n",
    "\n",
    "        clusterlabsNoProjs = sklearn.cluster.spectral_clustering((statNoProjs < 0.0001).astype(int), n_clusters=2,\n",
    "                                                         assign_labels='kmeans')\n",
    "        \n",
    "        clusterlabsRandProjs = sklearn.cluster.spectral_clustering((statRandProjs < 0.0001).astype(int), n_clusters=2,\n",
    "                                                         assign_labels='kmeans')\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        permutation = np.argmax([np.mean(clusterlabs == confounders[sz:, 0]), \n",
    "                        np.mean(clusterlabs != confounders[sz:, 0])])\n",
    "        if diagnostic:\n",
    "            print(permutation, np.max([np.mean(clusterlabs == confounders[sz:, 0]), \n",
    "                        np.mean(clusterlabs != confounders[sz:, 0])]))\n",
    "        clusterAccs.append(np.max([np.mean(clusterlabs == confounders[sz:, 0]), \n",
    "                        np.mean(clusterlabs != confounders[sz:, 0])]))\n",
    "\n",
    "        clusterAccsNoProjs.append(np.max([np.mean(clusterlabsNoProjs == confounders[sz:, 0]), \n",
    "                        np.mean(clusterlabsNoProjs != confounders[sz:, 0])]))\n",
    "        \n",
    "        clusterAccsRandProjs.append(np.max([np.mean(clusterlabsRandProjs == confounders[sz:, 0]), \n",
    "                        np.mean(clusterlabsRandProjs != confounders[sz:, 0])]))\n",
    "\n",
    "        ########MODEL ESTIMATION#########\n",
    "        Phat_ksa = getModelEstim(clusterlabs.astype(int), \n",
    "                             states[sz:,:], \n",
    "                             actions[sz:,:], \n",
    "                             nextstates[sz:,:],\n",
    "                            K=K, nStates=nStates, nActions=nActions, hard=True)\n",
    "        modelEstims.append(Phat_ksa)\n",
    "\n",
    "\n",
    "        ########CLASSIFICATION#########\n",
    "        priorclass = np.bincount(clusterlabs)/len(clusterlabs) \n",
    "        piclust = getPolicyEstim(states[sz:], actions[sz:], \n",
    "                                 K, nStates, nActions, preds=clusterlabs, hard=True)\n",
    "        startweights = getStartWeights(states[sz:], clusterlabs, K, nStates)\n",
    "        subspaceClass = classify(Phat_ksa, states[:sz,:], actions[:sz,:], \n",
    "                               nextstates[:sz,:], piclust, reg=1, \n",
    "                           prior=priorclass, startweights = startweights, labs=True)\n",
    "        if diagnostic:\n",
    "            print('Subspace Classification accuracy:', [np.mean(labels[:sz] == subspaceClass), \n",
    "                                                    np.mean(labels[:sz] != subspaceClass)][permutation])\n",
    "        classAccs.append(np.max([np.mean(labels[:sz] == subspaceClass), np.mean(labels[:sz] != subspaceClass)]))\n",
    "        \n",
    "        hsubs = np.array([geth(onehotsa[:sz,omegaone,:,:], \n",
    "                                         onehotsp[:sz,omegaone,:]), \n",
    "                                  geth(onehotsa[:sz,omegatwo,:,:], \n",
    "                                       onehotsp[:sz,omegatwo,:])], \n",
    "                 dtype=np.float32)\n",
    "        projclass = classifyProj(dataset[sz:], clusterlabs, hsubs, Phat_ksa, K, nStates, nActions)\n",
    "        classProjAccs.append(np.max([np.mean(labels[:sz] == projclass), np.mean(labels[:sz] != projclass)]))\n",
    "\n",
    "\n",
    "        ########EM ALGORITHM########\n",
    "        priorclass = np.bincount(clusterlabs)/len(clusterlabs) \n",
    "        piclust = getPolicyEstim(states[sz:], actions[sz:], \n",
    "                                 K, nStates, nActions, preds=clusterlabs, hard=True)\n",
    "\n",
    "        startweights = getStartWeights(states[sz:], clusterlabs, K, nStates)\n",
    "        maxapos = classify(Phat_ksa, states, actions, \n",
    "                               nextstates, piclust, reg=1, \n",
    "                           prior=priorclass, startweights = startweights, labs=True)\n",
    "        mleprobs = classify(Phat_ksa, states, actions, \n",
    "                               nextstates, piclust, reg=1, \n",
    "                            prior=priorclass, startweights = startweights, labs=False)\n",
    "        if diagnostic:\n",
    "            print('MAP estimate overall accuracy:', \n",
    "                  [np.mean(labels == maxapos), np.mean(labels != maxapos)][permutation])\n",
    "\n",
    "        # HARD EM \n",
    "        expectclass, modelestimclass, loglikclass = em(maxapos, \n",
    "                                Phat_ksa, states, actions, \n",
    "                            nextstates, labels=labels, \n",
    "                            K=K, nStates=nStates, nActions=nActions,\n",
    "                            prior = priorclass, reg = 1, max_iter=100,\n",
    "                                                   permute=False, permutation=permutation,\n",
    "                                                   checkin=1, hard=True, verbose=False)\n",
    "        hardClustEMs.append([expectclass, modelestimclass, loglikclass])\n",
    "        hardClustEMAccs.append(np.max([np.mean(labels == expectclass), np.mean(labels != expectclass)]))\n",
    "\n",
    "        # SOFT EM MODEL INIT\n",
    "        normprobs = np.exp(mleprobs-np.max(mleprobs))\n",
    "        regprobs = 0.8*(normprobs)/np.nansum(np.abs(normprobs), 0) + 0.1*np.ones(mleprobs.shape)\n",
    "        expectclasssoft, modelestimclasssoft, loglikclasssoft = em(regprobs, \n",
    "                                    Phat_ksa, states, actions, \n",
    "                                nextstates, labels, \n",
    "                                K=2, nStates=nStates, nActions=nActions,\n",
    "                                prior = priorclass, reg = 1, permute=False,\n",
    "                                permutation=permutation, checkin=1, hard=False, verbose=False)\n",
    "        softClustEMs.append([expectclasssoft, modelestimclasssoft, loglikclasssoft])\n",
    "        softClustEMAccs.append(np.max([np.mean(labels == expectclasssoft.argmax(0)),\n",
    "                                np.mean(labels != expectclasssoft.argmax(0))]))\n",
    "        \n",
    "        #HARD EM CLASS LABEL INIT\n",
    "        expecthard, modelestimhard, loglikhard = em(np.hstack([projclass, clusterlabs]), \n",
    "                                    Phat_ksa, states, actions, \n",
    "                                nextstates, labels, \n",
    "                                K=2, nStates=nStates, nActions=nActions,\n",
    "                                prior = priorclass, reg = 1, permute=False,\n",
    "                                permutation=permutation, checkin=1, hard=True, verbose=False)\n",
    "        hardClassEMs.append([expecthard, modelestimhard, loglikhard])\n",
    "        hardClassEMAccs.append(np.max([np.mean(labels == expecthard.argmax(0)),\n",
    "                                np.mean(labels != expecthard.argmax(0))]))\n",
    "        \n",
    "        #SOFT EM CLASS LABEL INIT\n",
    "        expect, modelestim, loglik = em(0.8*np.eye(K)[np.hstack([projclass, clusterlabs])].T +\n",
    "                                        0.1*np.ones((K, len(np.hstack([projclass, clusterlabs])))), \n",
    "                                    Phat_ksa, states, actions, \n",
    "                                nextstates, labels, \n",
    "                                K=2, nStates=nStates, nActions=nActions,\n",
    "                                prior = priorclass, reg = 1, permute=False,\n",
    "                                permutation=permutation, checkin=1, hard=False, verbose=False)\n",
    "        softClassEMs.append([expect, modelestim, loglik])\n",
    "        softClassEMAccs.append(np.max([np.mean(labels == expect.argmax(0)),\n",
    "                                np.mean(labels != expect.argmax(0))]))\n",
    "\n",
    "        #############BASE EM###############\n",
    "\n",
    "        labelsem = []\n",
    "        logliksem = []\n",
    "        for i in tqdm(range(30)):\n",
    "            randlabs = np.random.binomial(1, 0.5, size=len(dataset)).astype(int)\n",
    "            randmodel = getModelEstim(randlabs, states, actions, nextstates,\n",
    "                                      K, nStates, nActions, hard=True)\n",
    "            randlabs, randmodel, loglikrand = em(randlabs, randmodel,\n",
    "               states, actions, nextstates, labels, \n",
    "                                K=K, nStates=nStates, nActions=nActions,\n",
    "                                prior = priorclass, reg = 0, permute=True, permutation=permutation, checkin=1, verbose=False, hard=True)\n",
    "            labelsem.append(randlabs)\n",
    "            logliksem.append(loglikrand)\n",
    "        if diagnostic:\n",
    "            plt.figure(figsize=(12,7))\n",
    "            plt.scatter([max(np.mean(i == labels), np.mean(i != labels)) for i in labelsem], logliksem)\n",
    "            print(np.mean([max(np.mean(i == labels), np.mean(i != labels)) for i in labelsem]))\n",
    "            print(np.median([max(np.mean(i == labels), np.mean(i != labels)) for i in labelsem]))\n",
    "            print(np.max([max(np.mean(i == labels), np.mean(i != labels)) for i in labelsem]))\n",
    "            plt.xlabel('Accuracy')\n",
    "            plt.ylabel('Log-likelihood')\n",
    "            plt.title('Randomly Initialized Hard EM Algorithm')\n",
    "            plt.show()\n",
    "            plt.hist([max(np.mean(i == labels), np.mean(i != labels)) for i in labelsem])\n",
    "            plt.show()\n",
    "        hardEMAccs.append(np.mean([max(np.mean(i == labels), np.mean(i != labels)) for i in labelsem]))\n",
    "        hardEMs.append([labelsem, logliksem])\n",
    "\n",
    "        labelsemsoft = []\n",
    "        logliksemsoft = []\n",
    "        for i in tqdm(range(30)):\n",
    "            unifs = np.random.uniform(size=len(dataset))\n",
    "            randlabsoft = np.vstack([unifs, 1-unifs])\n",
    "            randmodelsoft = getModelEstim(randlabsoft, states, actions, nextstates,\n",
    "                                      K, nStates, nActions, hard=False)\n",
    "            randlabsoft, randmodelsoft, loglikrand = em(randlabsoft, randmodelsoft,\n",
    "           states, actions, nextstates, labels, \n",
    "                                K=K, nStates=nStates, nActions=nActions,\n",
    "                                prior = priorclass, reg = 0, permute=True, permutation=permutation, checkin=1, verbose=False, hard=False)\n",
    "            labelsemsoft.append(randlabsoft)\n",
    "            logliksemsoft.append(loglikrand)\n",
    "        if diagnostic:\n",
    "            plt.figure(figsize=(12,7))\n",
    "            plt.scatter([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)], \n",
    "                        logliksemsoft)\n",
    "            print(np.mean([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "            print(np.median([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "            print(np.max([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "            plt.ticklabel_format(style='plain',useOffset=False)\n",
    "            plt.xlabel('Accuracy')\n",
    "            plt.ylabel('Log-likelihood')\n",
    "            plt.title('Randomly Initialized Soft EM Algorithm')\n",
    "            plt.show()\n",
    "            plt.hist([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)])\n",
    "            plt.show()\n",
    "        softEMAccs.append(np.mean([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "        softEMs.append([labelsemsoft, logliksemsoft])\n",
    "        \n",
    "    clusterAccsTrials.append(clusterAccs)\n",
    "    clusterAccsNoProjsTrials.append(clusterAccsNoProjs)\n",
    "    clusterAccsRandProjsTrials.append(clusterAccsRandProjs)\n",
    "    classAccsTrials.append(classAccs)\n",
    "    classProjAccsTrials.append(classProjAccs)\n",
    "    hardClustEMAccsTrials.append(hardClustEMAccs)\n",
    "    softClustEMAccsTrials.append(softClustEMAccs)\n",
    "    hardEMAccsTrials.append(hardEMAccs)\n",
    "    softEMAccsTrials.append(softEMAccs)\n",
    "    hardClassEMAccsTrials.append(hardClassEMAccs)\n",
    "    softClassEMAccsTrials.append(softClassEMAccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1b89a-fbfc-4fb3-abf4-a93dacebf95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "randAccs = []\n",
    "dims = [2,4,6,8,12,16,24,32,40,48,56,64,72,80]\n",
    "for dim in dims:\n",
    "    randProjs = np.linalg.qr(np.random.normal(size=(nStates,nActions,nStates,dim)))[0]\n",
    "    statRandProjs = computeStat(hs, \n",
    "                            randProjs, numpy=False, smalldata=False, device=device, proj=True)\n",
    "    clusterRands = sklearn.cluster.spectral_clustering((statRandProjs < 0.0001).astype(int), n_clusters=2,\n",
    "                                                         assign_labels='kmeans')\n",
    "    randAccs.append(np.max([np.mean(clusterRands == confounders[sz:, 0]), \n",
    "                        np.mean(clusterRands != confounders[sz:, 0])]))\n",
    "        \n",
    "#clusterDiagnostics(statRandProjs, K=K, labels=confounders[sz:, 0],\n",
    "#               lo=0, hi=0.0005, step=0.000025) #0,0.01, 0.0001\n",
    "#plt.show()\n",
    "plt.plot(dims, 1-np.array(randAccs), label='Random Projections')\n",
    "plt.axhline(1-clusterAccs[-1], color='darkred', linestyle='dotted', label='Subspace Projections')\n",
    "plt.axhline(1-clusterAccsNoProjs[-1], color='orange', linestyle='dashed', label='No Projections')\n",
    "plt.xlabel('Dimension of Random Embedding')\n",
    "plt.ylabel('Clustering Error')\n",
    "plt.title('Clustering Error v.s. Random Embedding Dimension')\n",
    "plt.legend()\n",
    "plt.savefig('figs/jlRandEmbedding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac34dd-59ed-4af1-bea6-dd69531c7e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "#plt.figure(figsize=(16,9))\n",
    "plt.hist(statmns.flatten(), bins=200, density=True)#[1]\n",
    "#plt.hist(statmns.flatten(), bins=onehotsaclust.shape[0], density=True)[2]\n",
    "sns.kdeplot(statmns.flatten(), bw_adjust=0.2)\n",
    "#plt.title('')\n",
    "plt.xlabel('Distance Estimates')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density of Distance Estimates')\n",
    "plt.savefig('figs/distDens.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8223a-4d16-487d-93c8-75633cf2e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterDiagnostics(statmns, K=K, labels=confounders[sz:, 0],\n",
    "                           lo=0, hi=0.0005, step=0.000025, figsize=(8,6))\n",
    "plt.ylabel('Clustering Accuracy')\n",
    "plt.title('Accuracy Against Thresholds')\n",
    "plt.savefig('figs/clustAccs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d2f4f9-8da0-4ba3-88d5-cb26b2be3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)], \n",
    "            logliksemsoft)\n",
    "print(np.mean([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "print(np.median([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "print(np.max([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)]))\n",
    "plt.ticklabel_format(style='plain',useOffset=False)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "plt.title('Randomly Initialized Soft EM Algorithm')\n",
    "plt.savefig('figs/softEM.png')\n",
    "plt.show()\n",
    "plt.hist([max(np.mean(i == labels), np.mean(i != labels)) for i in np.array(labelsemsoft).argmax(axis=1)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc7d84-af5c-4efc-a585-bc10a70ce2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,9))\n",
    "print(np.mean(np.array(clusterAccsTrials),0)[-1])\n",
    "plt.plot(horizons, 1-np.mean(np.array(clusterAccsTrials),0), label='With Subspaces')\n",
    "plt.plot(horizons, 1-np.mean(np.array(clusterAccsNoProjsTrials),0), label='Without Subspaces',\n",
    "        linestyle='--')\n",
    "plt.ylabel(\"Clustering Error\")\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"Clustering Error vs Trajectory Length\")\n",
    "plt.legend()\n",
    "plt.savefig('figs/clust.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7bab6-6043-4ef9-a282-ff6186a4bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,9))\n",
    "plt.plot(horizons, 1-np.mean(np.array(clusterAccsTrials),0), label='With Subspaces')\n",
    "plt.plot(horizons, 1-np.mean(np.array(clusterAccsNoProjsTrials),0), label='Without Subspaces',\n",
    "        linestyle='--')\n",
    "plt.plot(horizons, 1-np.mean(np.array(clusterAccsRandProjsTrials),0), label='Random Subspaces',\n",
    "        linestyle='dashdot')\n",
    "plt.ylabel(\"Clustering Error\")\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"Clustering Error vs Trajectory Length\")\n",
    "plt.legend()\n",
    "plt.savefig('figs/clustRand.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08d3f9-00e5-4d08-a584-abeab69ed30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(clusterAccsTrials),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110e37b-dfb9-448a-9bac-2a01b67f522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,9))\n",
    "plt.plot(horizons, 1-np.mean(np.array(classAccsTrials),0), label='E-Step')\n",
    "plt.plot(horizons, 1-np.mean(np.array(classProjAccsTrials),0), label='Classification (Alg. 3)',\n",
    "        linestyle='--')\n",
    "plt.ylabel(\"Classification Error\")\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"Classification Error vs Trajectory Length\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae9fb2-2af9-4a02-8481-db7f4dfbfcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,9))\n",
    "'''\n",
    "plt.plot(horizons, 1-np.median(np.array(hardClustEMAccsTrials),0),\n",
    "         label='Hard EM Cluster Init')\n",
    "plt.plot(horizons, 1-np.median(np.array(hardEMAccsTrials),0),\n",
    "        label='Hard EM')\n",
    "'''  \n",
    "print(np.mean(np.array(softClassEMAccsTrials),0)[-1])\n",
    "plt.plot(horizons, 1-np.mean(np.array(softClassEMAccsTrials),0),\n",
    "         label='Soft EM Class+Cluster Init')\n",
    "plt.plot(horizons, 1-np.mean(np.array(softClustEMAccsTrials),0),\n",
    "         label='Soft EM Cluster Init',\n",
    "        linestyle='--')\n",
    "plt.plot(horizons, 1-np.mean(np.array(softEMAccsTrials),0),\n",
    "        label='Soft EM Random Init',\n",
    "        linestyle='dashdot')\n",
    "#plt.plot(horizons, 1-np.mean(np.array(hardClustEMAccsTrials),0),\n",
    "#         label='Hard EM Cluster Init',\n",
    "#        linestyle='--')\n",
    "#plt.plot(horizons, 1-np.mean(np.array(hardEMAccsTrials),0),\n",
    "#        label='Hard EM Random Init',\n",
    "#        linestyle='dashdot')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"End-to-End Performance Comparison\")\n",
    "plt.legend()\n",
    "plt.savefig('figs/emClust.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188f814d-e0d3-44df-a22f-5b5e0ddd031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(16,9))\n",
    "'''\n",
    "plt.plot(horizons, 1-np.median(np.array(hardClustEMAccsTrials),0),\n",
    "         label='Hard EM Cluster Init')\n",
    "plt.plot(horizons, 1-np.median(np.array(hardEMAccsTrials),0),\n",
    "        label='Hard EM')\n",
    "'''  \n",
    "print(np.mean(np.array(softClassEMAccsTrials),0)[-1])\n",
    "plt.plot(horizons, 1-np.mean(np.array(softClustEMAccsTrials),0),\n",
    "         label='Soft EM Cluster Init')\n",
    "plt.plot(horizons, 1-np.mean(np.array(softEMAccsTrials),0),\n",
    "        label='Soft EM Random Init')\n",
    "plt.plot(horizons, 1-np.mean(np.array(hardClustEMAccsTrials),0),\n",
    "         label='Hard EM Cluster Init',\n",
    "        linestyle='--')\n",
    "plt.plot(horizons, 1-np.mean(np.array(hardEMAccsTrials),0),\n",
    "        label='Hard EM Random Init',\n",
    "        linestyle='--')\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Trajectory Length\")\n",
    "plt.title(\"Soft v.s. Hard EM Algorithm\")\n",
    "plt.legend()\n",
    "plt.savefig('figs/emSoftHard.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e07fd-ff3e-4d84-9a23-9a4948c52fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "m = 1-statmns #need similarity matrix\n",
    "# shuffle\n",
    "perm = np.random.permutation(len(m))\n",
    "m = m[perm][:, perm]\n",
    "\n",
    "# reorder\n",
    "y = m[np.triu_indices(len(m), k=1)]\n",
    "Z = linkage(y, method='single', optimal_ordering=True)\n",
    "perm = np.ravel(Z[:, :2]).astype(np.int32)\n",
    "perm = perm[perm < len(m)]\n",
    "m = m[perm][:, perm]\n",
    "\n",
    "#plt.figure(figsize=(16,9))\n",
    "plt.imshow(1-m)\n",
    "plt.title('Block Structure of Squared Distances')\n",
    "plt.savefig('figs/blocks.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ffe96-85bc-4c32-b014-03596e2b6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, vecs = getEig(onehotsa[:sz], onehotsp[:sz], omegaone, omegatwo, 10000, wt=True)\n",
    "plt.hist((np.sort(vals, axis=-1)**2).mean((0,1)), bins=nStates)\n",
    "plt.title('Histogram of Mean Ordered Eigenvalue Energy')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Eigenvalue Energy')\n",
    "plt.savefig('figs/eigEnergy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0010cde-0a1b-4de1-8826-cce22659554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_min = np.minimum(getN_sa(dataset[dataset[:,:,2]==0], nStates, nActions, burnin=0, reshape=False)/len(dataset[dataset[:,:,2]==0]),\n",
    "           getN_sa(dataset[dataset[:,:,2]==1], nStates, nActions, burnin=0, reshape=False)/len(dataset[dataset[:,:,2]==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d1e25-2771-42eb-95a1-98e0005db72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(d_min.flatten(), np.linalg.norm((P[0])-(P[1]), axis=-1).flatten())\n",
    "plt.xlabel('Estimated Occupancy Measures')\n",
    "plt.ylabel('True Model Separation')\n",
    "plt.title('Model Separation v.s. Occupancy Measures')\n",
    "plt.savefig('figs/trueModelSep.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78f25c-24cb-4a05-a2b9-17dac9e2e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(d_min.flatten(), np.linalg.norm((modelEstims[-1][0])-(modelEstims[-1][1]), axis=-1).flatten())\n",
    "plt.xlabel('Estimated Occupancy Measures', fontsize=13)\n",
    "plt.ylabel('Clustering-Estimated Model Separation', fontsize=13)\n",
    "plt.title('Model Separation v.s. Occupancy Measures')\n",
    "plt.savefig('figs/clustModelSep.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
